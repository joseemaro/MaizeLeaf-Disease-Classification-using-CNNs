{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Instalar dependencias\n",
    "!pip install -q tensorflow opencv-python numpy matplotlib scikit-learn pandas\n",
    "\n",
    "# 1) Imports + seed\n",
    "import os, re, cv2, numpy as np, tensorflow as tf, matplotlib.pyplot as plt, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "SEED = 123\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# 2) Configuración\n",
    "DATA_DIR = \"/ruta/a/PlantVillage/color\"   # <-- CAMBIAR a tu carpeta\n",
    "OUT_DIR = \"models\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = 300   # EfficientNetB3\n",
    "BATCH = 32\n",
    "\n",
    "# Patrón para clases de maíz\n",
    "MAIZ_REGEX = r\"^Corn(?:_\\(maize\\))?___\"\n",
    "LIMPIA = lambda s: re.sub(MAIZ_REGEX, \"\", s).replace(\"_\", \" \").strip()\n",
    "\n",
    "# 3) Filtrar solo maíz\n",
    "filepaths, labels = [], []\n",
    "for cls in os.listdir(DATA_DIR):\n",
    "    d = os.path.join(DATA_DIR, cls)\n",
    "    if not os.path.isdir(d): \n",
    "        continue\n",
    "    if re.match(MAIZ_REGEX, cls, flags=re.IGNORECASE):\n",
    "        for f in os.listdir(d):\n",
    "            if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
    "                filepaths.append(os.path.join(d,f))\n",
    "                labels.append(LIMPIA(cls))\n",
    "\n",
    "df = pd.DataFrame({\"filepath\": filepaths, \"label\": labels})\n",
    "classes = sorted(df[\"label\"].unique())\n",
    "print(\"Clases:\", classes, \"Total imágenes:\", len(df))\n",
    "\n",
    "# 4) Splits\n",
    "train_df, tmp_df = train_test_split(df, train_size=0.8, stratify=df[\"label\"], random_state=SEED, shuffle=True)\n",
    "valid_df, test_df = train_test_split(tmp_df, train_size=0.5, stratify=tmp_df[\"label\"], random_state=SEED, shuffle=True)\n",
    "\n",
    "# 5) Preprocesado CLAHE + AMF aprox\n",
    "CLAHE_CLIP, CLAHE_TILE = 2.0, (8,8)\n",
    "def preprocess_cv(rgb):\n",
    "    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
    "    L,a,b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP, tileGridSize=CLAHE_TILE)\n",
    "    Lc = clahe.apply(L)\n",
    "    rgb_c = cv2.cvtColor(cv2.merge([Lc,a,b]), cv2.COLOR_LAB2RGB)\n",
    "    rgb_c = cv2.medianBlur(rgb_c, 3)\n",
    "    rgb_r = cv2.resize(rgb_c, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    return rgb_r.astype(\"float32\")/255.0\n",
    "\n",
    "# 6) tf.data pipeline\n",
    "label_to_id = {c:i for i,c in enumerate(classes)}\n",
    "id_to_label = {i:c for c,i in label_to_id.items()}\n",
    "\n",
    "def gen(rows):\n",
    "    for _,r in rows.iterrows():\n",
    "        yield r[\"filepath\"], label_to_id[r[\"label\"]]\n",
    "\n",
    "def load_and_preprocess(path, y):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.numpy_function(preprocess_cv, [img], Tout=tf.float32)\n",
    "    img.set_shape((IMG_SIZE, IMG_SIZE, 3))\n",
    "    y = tf.one_hot(y, depth=len(classes))\n",
    "    return img, y\n",
    "\n",
    "def make_ds(dataframe, shuffle=False):\n",
    "    ds = tf.data.Dataset.from_generator(lambda: gen(dataframe), output_signature=(\n",
    "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    ))\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(4096, seed=SEED)\n",
    "    ds = ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(train_df, shuffle=True)\n",
    "valid_ds = make_ds(valid_df)\n",
    "test_ds  = make_ds(test_df)\n",
    "\n",
    "# 7) Modelo EfficientNetB3\n",
    "base = keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\",\n",
    "                                         input_shape=(IMG_SIZE,IMG_SIZE,3), pooling=\"avg\")\n",
    "x = layers.BatchNormalization()(base.output)\n",
    "x = layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(len(classes), activation=\"softmax\")(x)\n",
    "model = keras.Model(base.input, out)\n",
    "\n",
    "# Warm-up\n",
    "for l in base.layers: \n",
    "    l.trainable = False\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "cb = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "model.fit(train_ds, validation_data=valid_ds, epochs=5, callbacks=cb, verbose=1)\n",
    "\n",
    "# Fine-tune\n",
    "for l in base.layers: \n",
    "    l.trainable = True\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_ds, validation_data=valid_ds, epochs=20, callbacks=cb, verbose=1)\n",
    "\n",
    "# 8) Evaluación y guardado\n",
    "print(\"Test:\", model.evaluate(test_ds, verbose=0))\n",
    "MODEL_PATH = os.path.join(OUT_DIR, \"maiz_efficientnetb3.h5\")\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Modelo guardado en:\", MODEL_PATH)\n",
    "\n",
    "# 9) Inferencia sobre una foto\n",
    "FOTO_EXTERNA = \"/ruta/a/tu_foto.jpg\"  # <-- CAMBIAR\n",
    "def cargar_rgb(path):\n",
    "    bgr = cv2.imread(path)\n",
    "    if bgr is None:\n",
    "        raise FileNotFoundError(f\"No se pudo leer {path}\")\n",
    "    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "try:\n",
    "    rgb = cargar_rgb(FOTO_EXTERNA)\n",
    "    x  = preprocess_cv(rgb)\n",
    "    probs = model.predict(x[None,...], verbose=0)[0]\n",
    "    k = int(np.argmax(probs)); p = float(probs[k])\n",
    "    print(f\"pred: {id_to_label[k]}  p={p:.3f}\")\n",
    "    plt.imshow(rgb); plt.axis(\"off\"); plt.title(f\"{id_to_label[k]}  p={p:.3f}\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Error en inferencia:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
