{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python numpy matplotlib tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0) Imports\n",
    "import os, cv2, numpy as np, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Config\n",
    "MODEL_PATH = \"models/maiz_efficientnetb3.h5\"   # cambia a tu ruta\n",
    "CLASSES = [\"common_rust\", \"gray_leaf_spot\", \"northern_leaf_blight\", \"healthy\"]\n",
    "THRESH_OTHER = 0.60     # umbral para decidir \"otra\" (ajustar con validación)\n",
    "CLAHE_CLIP = 2.0\n",
    "CLAHE_TILE = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Cargar modelo\n",
    "model = keras.models.load_model(MODEL_PATH, compile=False)\n",
    "H, W = model.input_shape[1], model.input_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdab3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Preprocesado del paper: RGB→Lab, CLAHE(L), mediana, back→RGB, resize y escalar\n",
    "def preprocess_rgb(img_rgb, size=(H, W)):\n",
    "    lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "    L, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP, tileGridSize=CLAHE_TILE)\n",
    "    Lc = clahe.apply(L)\n",
    "    lab_c = cv2.merge([Lc, a, b])\n",
    "    rgb_c = cv2.cvtColor(lab_c, cv2.COLOR_LAB2RGB)\n",
    "    rgb_c = cv2.medianBlur(rgb_c, ksize=3)   # aproximación a AMF\n",
    "    rgb_r = cv2.resize(rgb_c, size, interpolation=cv2.INTER_AREA)\n",
    "    x = rgb_r.astype(np.float32) / 255.0\n",
    "    return x\n",
    "\n",
    "def load_image_for_infer(path):\n",
    "    bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        raise ValueError(f\"No se pudo leer: {path}\")\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    x = preprocess_rgb(rgb)\n",
    "    return rgb, np.expand_dims(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Inferencia + “otra”\n",
    "def predict_image(path):\n",
    "    rgb_orig, x = load_image_for_infer(path)\n",
    "    probs = model.predict(x, verbose=0)[0]\n",
    "    k = int(np.argmax(probs))\n",
    "    p = float(probs[k])\n",
    "    label = CLASSES[k]\n",
    "    is_other = p < THRESH_OTHER\n",
    "    return {\"orig\": rgb_orig, \"probs\": probs, \"label\": label, \"pmax\": p, \"is_other\": is_other}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87045a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) Grad-CAM para visualizar y estimar % de área afectada (aprox)\n",
    "def last_conv_layer(m):\n",
    "    # intenta detectar la última capa conv2d si no sabés el nombre\n",
    "    for layer in reversed(m.layers):\n",
    "        if isinstance(layer, keras.layers.Conv2D):\n",
    "            return layer.name\n",
    "    raise ValueError(\"No se encontró Conv2D\")\n",
    "\n",
    "def grad_cam(m, img_array, class_index=None, layer_name=None):\n",
    "    if layer_name is None:\n",
    "        layer_name = last_conv_layer(m)\n",
    "    conv_layer = m.get_layer(layer_name)\n",
    "    grad_model = keras.models.Model([m.inputs], [conv_layer.output, m.outputs])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, preds = grad_model(img_array, training=False)\n",
    "        if class_index is None:\n",
    "            class_index = int(tf.argmax(preds[0]))\n",
    "        class_channel = preds[:, class_index]\n",
    "    grads = tape.gradient(class_channel, conv_out)\n",
    "    weights = tf.reduce_mean(grads, axis=(1, 2), keepdims=True)\n",
    "    cam = tf.nn.relu(tf.reduce_sum(weights * conv_out, axis=-1))[0]\n",
    "    cam = cam.numpy()\n",
    "    cam -= cam.min()\n",
    "    cam /= (cam.max() + 1e-8)\n",
    "    cam = cv2.resize(cam, (img_array.shape[2], img_array.shape[1]))\n",
    "    return cam\n",
    "\n",
    "def lesion_percent_from_cam(cam, q=0.7):\n",
    "    thr = np.quantile(cam, q)\n",
    "    mask = (cam >= thr).astype(np.uint8)\n",
    "    return 100.0 * mask.mean(), mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3dbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6) Ejecutar sobre una foto tuya\n",
    "# path_foto = \"mis_fotos/hoja_maiz.jpg\"\n",
    "# out = predict_image(path_foto)\n",
    "# cam = grad_cam(model, out_img := np.expand_dims(preprocess_rgb(out[\"orig\"]), 0))\n",
    "# perc, mask = lesion_percent_from_cam(cam, q=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f805f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7) Mostrar resultados\n",
    "def show_result(path_foto):\n",
    "    out = predict_image(path_foto)\n",
    "    x = np.expand_dims(preprocess_rgb(out[\"orig\"]), 0)\n",
    "    cam = grad_cam(model, x)\n",
    "    perc, mask = lesion_percent_from_cam(cam, q=0.7)\n",
    "\n",
    "    title = \"otra\" if out[\"is_other\"] else out[\"label\"]\n",
    "    print(f\"pred: {title}  pmax={out['pmax']:.3f}\")\n",
    "    if not out[\"is_other\"]:\n",
    "        print(f\"% área afectada (aprox, CAM>=p{70}): {perc:.1f}%\")\n",
    "\n",
    "    # overlays\n",
    "    heat = (plt.cm.jet(cam)[:, :, :3] * 255).astype(np.uint8)\n",
    "    overlay = cv2.addWeighted(out[\"orig\"], 0.6, heat, 0.4, 0)\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1); plt.imshow(out[\"orig\"]); plt.axis(\"off\"); plt.title(\"original\")\n",
    "    plt.subplot(1,3,2); plt.imshow(overlay);    plt.axis(\"off\"); plt.title(\"Grad-CAM\")\n",
    "    plt.subplot(1,3,3); plt.imshow(mask, cmap=\"gray\"); plt.axis(\"off\"); plt.title(\"lesión binaria\")\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60442bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo:\n",
    "# show_result(path_foto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
